#Terminology

|Term|Description|
| --:|:--------- |
|framework|We use the word framework loosely to refer to any HTTP stackâ€”a full-stack framework, a micro-framework, or even a web platform such as Rack, Servlet, or plain PHP.|
|permutation| A combination of attributes that compose a full technology stack being tested (such as node.js paired with MongoDB or node.js paired with MySQL). Some frameworks have seen many permutations contributed by the community; others only one or two.|
|test type|One of the workloads we exercise, such as JSON serialization, single-query, multiple-query, fortunes, data updates, and plaintext.|
|test|An individual test is a measurement of the performance of a permutation's implementation of a test type. For example, a test might be measuring Wicket paired with MySQL running the single-query test type.|
|implementation|Sometimes called "test implementations," these are the bodies of code and configurations created to test permutations according to the requirements. These are frequently contributed by the developer community. Basically, together with the toolset, test implementations are the meat of this project.|
|toolset|A set of Python scripts that run our tests.|
|run|An execution of the benchmark toolset across the suite of test implementations, either in full or in part, in order to capture results for any purpose.|
|preview|A capture of data from a run used by project participants to sanity-check prior to an official round.|
|round|A posting of "official" results on this web site. This is mostly for ease of consumption by readers and good-spirited and healthy competitive bragging rights. For in-depth analysis, we encourage you to examine the source code and run the tests on your own hardware.|

#Server Roles

When running the benchmark suite, we use three server roles.  These roles can be fulfilled by three distinct computers (physical hardware), three virtual machines, by a single computer acting in all three roles simultaneously, or any other blend.

The full benchmark requires at least three server roles:

* `app server`: The server that hosts each framework during a run, inclusive of web servers where applicable.
* `load server`: The server that generates client load during a run. Also known as the `client` or `client machine`.
* `database server`: The server that runs the databases used during a run. Also known as the `DB server`.

This codebase (`TechEmpower/FrameworkBenchmarks` aka `TFB`) must be run on 
the `app server`. The codebase contains a number of `framework directories`, each 
of which contains one or more `framework test implementations`. While our current setup has 
many directories, we are working to consolidate related code into fewer directories with more tests per directory.

When run, `TFB` will: 

* Select which framework tests are to be run based on command-line arguments you provide
* Install the necessary software (both on the `app server` and other servers)
* Launch the framework(s) you've requested, each in turn
* Launch the necessary database servers
* Access the URIs listed in [the requirements](http://www.techempower.com/benchmarks/#section=code) and verify the responses
* Launch the load generation software on the `load server`
* Gather the results
* Halt the framework, and repeat for the next framework as specified by command-line arguments
